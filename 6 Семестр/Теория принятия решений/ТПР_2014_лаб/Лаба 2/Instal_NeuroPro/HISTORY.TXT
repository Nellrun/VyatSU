	Версия 0.25
Дополнения и изменения в сравнении с ранее распространявшейся версией 0.1

- Новый формат файлов проекта. Формат версии 0.1 не поддерживается
- Процесс обучения и упрощения более устойчив к попаданию в локальный
  минимум функции оценки
- Кнопка <Копия сети> в окне проекта - создание новой сети по образцу текущей.
  В новой сети наследуется структура и подача сигналов текущей сети
- Обработка качественных признаков (дискретнозначных признаков, принимающих
  конечное число выделенных значений):
  - Переключение между количественным и качественным состоянием для признака
  - Определение числа и диапазонов дискретных состояний признака (до 20
    состояний для признака), автоматическое формирование набора состояний по
    файлу данных
  - Отношение предшествования для состояний качественного признака
  - Контрастирование входных качественных признаков _по_состояниям_, что
    выделяет наиболее значимые дискр. состояния кач. признака
- Кнопка <Обучение сети> в тулбаре
- Переделан алгоритм равномерного упрощения сети - упрощается нейрон с
  максимальным числом синапсов, а если таких нейронов несколько - то
  выбирается нейрон с наименее значимым синапсом - ранее удалялись синапсы
  одного нейрона первого слоя, потом - другого нейрона, далее - нейронов
  след. слоя
- Сделана возможность выбора фиксированного набора весов при бинаризации
  синапсов:
  - -1,1
  - -0.5,0.5,-1,1
  - -0.25,0.25,-0.5,0.5,-0.75,0.75,-1,1
  - -0.1,0.1,-0.2,0.2,...,-0.9,0.9,-1,1
  Выбор сохраняется в файле проекта
- Сделан ввод в обучение весов бинаризованных синапсов при переходе от
  одного диапазона выделенных значений к другому
- При удалении входного признака теперь можно по желанию пользователя
  перестраивать задачник - задачник может расширяться теми примерами,
  где отсутствовали значения удаленного признака
- Сделано контрастирование нейронов
- Сделано переименование сети
- Сделана процедура трансляции форматов файлов данных
- Добавлен BFGS-метод оптимизации
- В меню добавлен пункт "Анализ обучающего множества"
  - Оценивается константа Липшица обучающей выборки (о том, что это за зверь и
    как его использовать - читать книжку Горбань А.Н., Россиев Д.А. "Нейронные
    сети на персональном компьютере"), вычисляется минимум нормы разности
    входных векторов
  - Формируется и отображается набор конфликтных примеров (в расчете
    предыдущих величин конфликтные примеры не участвуют)
- Значимости входов можно сохранять в текстовом файле для последующего 
  импорта в Excel и построения диаграмм там
- Убран переключатель оценки в окне проекта. Теперь для количественных
  признаков всегда устанавливается МНК с люфтом, а для качественных -
  тот или иной вариант оценки типа расстояния до множества
- Сделано отображение невязки (для количественных полей) и уверенности сети
  в ответе (для качественных). Неправильно решенные примеры, неуверенно
  решенные примеры и правильно решенные примеры отображаются разными цветами.
  Прогноз сети для отсутствующих данных отображается отдельным цветом.
  Выводится статистическая информация о числе правильно и неправильно
  решенных примеров. Для качественных признаков дополнительно выводится
  число правильно и неправильно решенных примеров каждого класса.
  Для количественных полей выводятся максимальная и средняя ошибки прогноза.
- Результат тестирования можно сохранять в текстовом файле. Далее этот файл
  можно импортировать в Excel и строить графики ошибки прогноза (особенно
  полезно, когда таблица данных представляет временной ряд - можно поглядеть
  на участки "разладки")
- Добавлено меню для работы с таблицей данных:
  - Вставка новой записи
  - Добавление записи в конец таблицы
  - Удаление текущей записи

Ну и конечно
- Исправлены обнаруженные ошибки
- Внесены новые ошибки :)
